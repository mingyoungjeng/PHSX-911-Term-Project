{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physics 911 Term Project\n",
    "### Mingyoung Jeng\n",
    "\n",
    "Adapting aspects of Efficiently Updatable Neural Networks (NNUE) into quantum machine learning circuits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Efficiently Updatable Neural Networks (NNUE)\n",
    "\n",
    "NNUEs are a type of neural network that has shown great advantage in engines designed to play shogi and chess, where they are used for positional evaluation. Compared to deep neural-networks like those used in DeepMind's Alpha- series of engines (e.g. AlphaZero in chess), they can be efficiently run on CPUs duea structure prioritizing efficiency.\n",
    "\n",
    "![](https://github.com/glinscott/nnue-pytorch/raw/master/docs/img/A-768-8-8-1.svg) \n",
    "\n",
    "[Source](https://github.com/glinscott/nnue-pytorch/blob/master/docs/nnue.md)\n",
    "\n",
    "First, the networks are shallow, but fully interconnected between nodes, resulting in a relatively small network. Second, they are sparse, meaning they expect the majority of inputs to be $0$, which enables efficient lazy updates between iterations.\n",
    "\n",
    "Given the state of current quantum machines, the same motivations behind NNUEs could also hold for QPUs, especially the desire for shallower, less costly networks.\n",
    "\n",
    "Sources: [Original Paper (JPN)](https://github.com/ynasu87/nnue/blob/master/docs/nnue.pdf), [Original Paper (Unofficial English translation)](https://github.com/asdfjkl/nnue/blob/main/nnue_en.pdf), [GitHub](https://github.com/glinscott/nnue-pytorch/blob/master/docs/nnue.md), [saumikn](https://saumikn.com/blog/a-brief-guide-to-stockfish-nnue/), [Chess.com](https://www.chess.com/blog/the_real_greco/evolution-of-a-chess-fish-what-is-nnue-anyway)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantum Variational Algorithms\n",
    "\n",
    "As a near-term classification algorithm, this algorithm formed the foundation upon which I implemented my NNUE-inspired circuit design. \n",
    "\n",
    "![](https://learn.qiskit.org/content/quantum-machine-learning/images/vqc/vqc.svg)\n",
    "\n",
    "The general concept depends on two parameterized circuits which have a fixed structure whose gates (rotation gates, specifically) can be updated between executions to different values. The first circuit, $\\phi$ is a data encoding circuit, which parses the given inputs, and the second, $W(\\overrightarrow{\\theta})$, a variational circuit which returns a series of labels (measurements). These outputs are handled classicially by passing them into a cost function which is used by a gradient-descent optimizer to decide on the next iteration's set of parameters.\n",
    "\n",
    "Source: [Qiskit](https://learn.qiskit.org/course/machine-learning/variational-classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Objective\n",
    "\n",
    "Determine a parameterized quantum circuit that reflects the principal benefits of NNUEs.\n",
    "* Efficient updating\n",
    "* Sparse\n",
    "* Shallow\n",
    "* Fully interconnected\n",
    "\n",
    "The closest analog in the quantum space that fulfills the same role of efficient iteration in NNUEs is circuit parameterization. While all quantum circuit need repeated measurement to achieve accurate results, circuit parameterization does allow the structure of a circuit to remain constant over all executions, with only the parameters needing to be updated.\n",
    "\n",
    "I have chosen to interpret \"sparseness\" to mean that if any qubit is found to be in its ground state, it shouldn't have any effect on the final result.\n",
    "\n",
    "Circuit depth is already a primary constraint in contemporary quantum algorithm design due to decoherence. Here, I specifically tried to target a $O(n)$ depth, where $n$ is the number of qubits.\n",
    "\n",
    "Fully interconnected is already a natural concept in the quantum domain, due to superposition and entanglement. In practice, I looked for a circuit that ensured each qubit could have an effect on the final measurement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adapting a typical variational circuit algorithm\n",
    "\n",
    "As a control, we have the `qiskit` tutorial code for a variational classifier adapted to provide \"evaluation\" between $0.0-1.0$, as seen in classical NNUEs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import Aer\n",
    "from qiskit.utils import algorithm_globals\n",
    "from qiskit_ibm_runtime import QiskitRuntimeService\n",
    "algorithm_globals.random_seed = 69420\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(algorithm_globals.random_seed)\n",
    "\n",
    "num_qubits = 7\n",
    "num_training = 40\n",
    "num_test = 20\n",
    "\n",
    "local = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select a backend**\n",
    "\n",
    "The `local` flag above can be used to toggle between one's local `Aer` simulator or use a quantum computer via the Qiskit runtime service that is recommended for running this type of application on real quantum hardware. However, I've found the service to be intermittent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if local:\n",
    "    backend = Aer.get_backend('aer_simulator')\n",
    "else:\n",
    "    service = QiskitRuntimeService(\n",
    "        channel='ibm_quantum',\n",
    "        instance='ibm-q-research-2/uni-kansas-1/main',\n",
    "    )\n",
    "    # backend = service.get_backend('ibmq_qasm_simulator')\n",
    "    backend = service.least_busy(simulator=False, operational=True, min_num_qubits=num_qubits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"evaluation\" function can be anything in general. However, In this case, I chose an evaluation function that outputs the normalized entropy of the input statevector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(psi: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    This function gives the \"correct\" output for any input data\n",
    "    Args:\n",
    "        psi (list): Input statevector\n",
    "    Returns:\n",
    "        float: Value between 0.0 and 1.0\n",
    "    \"\"\"\n",
    "    \n",
    "    return -sum(psi * np.log2(psi + 1e-10)) / len(psi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_data(qubits: int):\n",
    "    \"\"\"\n",
    "    Generates random sparse datasets\n",
    "    Args:\n",
    "        qubits (int): number of qubits in statevector\n",
    "    Returns:\n",
    "        np.ndarray: statevector\n",
    "    \"\"\"\n",
    "    psi = np.zeros(2**qubits)\n",
    "    n = np.random.randint(1, 2**(qubits-1))\n",
    "    psi[:n] = np.random.rand(n)\n",
    "    np.random.shuffle(psi)\n",
    "    psi = psi / np.linalg.norm(psi)\n",
    "    return psi\n",
    "\n",
    "train_data = [random_data(num_qubits) for _ in range(num_training)]\n",
    "train_labels = [eval(x) for x in train_data]\n",
    "\n",
    "test_data = [random_data(num_qubits) for _ in range(num_test)]\n",
    "test_labels = [eval(x) for x in test_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This circuit is the template upon which $\\theta$ parameters are bound. Specifically, it is the circuit used in the [`qiskit` variational circuits tutorial](https://learn.qiskit.org/course/machine-learning/variational-classification#variational-3-0), called [`TwoLocal`](https://qiskit.org/documentation/stubs/qiskit.circuit.library.TwoLocal.html). This is what I will be comparing my circuit design against.\n",
    "\n",
    "The tutorial used a [`ZZFeatureMap`](https://qiskit.org/documentation/stubs/qiskit.circuit.library.ZZFeatureMap.html) for the data encoding circuit, but those could only go up to 3 qubits, so I opted to use the general `initialize` function instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit.library import TwoLocal\n",
    "\n",
    "QML = QuantumCircuit(num_qubits, 1)\n",
    "\n",
    "var = TwoLocal(num_qubits, ['ry', 'rz'], 'cz', reps=2)\n",
    "QML.compose(var, inplace=True)\n",
    "        \n",
    "QML.measure(0, 0)\n",
    "\n",
    "num_variational = len(var.ordered_parameters)\n",
    "        \n",
    "QML.decompose().draw('mpl', reverse_bits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function was lifted and modified from the aforementioned `qiskit` tutorial. It adds in the `initialize` data encoding portion, binds the passed parameters, and returns the final quantum circuit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circuit_instance(data, variational):\n",
    "    qc = QuantumCircuit(num_qubits)\n",
    "    qc.initialize(data)\n",
    "    qc.compose(QML.assign_parameters(variational), inplace=True)\n",
    "    \n",
    "    return qc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general structure of these methods was taken from the `qiskit` tutorial. `label_probability` takes in the measurement counts of a circuit execution and returns the probabilities. `evaluation_probability` takes in parameters to generate circuits, executes them, and uses `label_probability` to return the probabilities. Finally, the `cost_function` is calculated from the `label_probability`. In a general ML context, the cost function is the metric to minimize (smaller $\\rightarrow$ more correct)\n",
    "\n",
    "I modified the `label_probability` and `cost_function` methods to suit my modified problem set (evaluation vs classification). I also added `QiskitRuntime` compatibility to the `evaluation_probability` function via the [`Sampler`](https://qiskit.org/documentation/stubs/qiskit.primitives.Sampler.html) primitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import execute\n",
    "from qiskit_ibm_runtime import Session, Sampler\n",
    "sampler = None # Save for later\n",
    "\n",
    "def label_probability(counts):\n",
    "    if \"0\" not in counts.keys():\n",
    "        return 0\n",
    "    return counts[\"0\"] / sum(counts.values())\n",
    "\n",
    "def evaluation_probability(data, variational):\n",
    "    \"\"\"Classify data points using given parameters.\n",
    "    Args:\n",
    "        data (list): Set of data points to classify\n",
    "        variational (list): Parameters for `VAR_FORM`\n",
    "    Returns:\n",
    "        list[dict]: Probability of circuit classifying\n",
    "                    each data point as 0 or 1.\n",
    "    \"\"\"\n",
    "    circuits = [circuit_instance(d, variational) for d in data]\n",
    "    results = execute(circuits, backend).result() if local else sampler.run(circuits).result()\n",
    "    evals = [label_probability(results.get_counts(c)) for c in circuits]\n",
    "    \n",
    "    return evals\n",
    "\n",
    "def cost_function(data, labels, variational):\n",
    "    classifications = evaluation_probability(data, variational)\n",
    "    cost = sum([np.abs(classification - label) for classification, label in zip(classifications, labels)])\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is simply the tutorial's optimizer refactored to be compatible with `QiskitRuntime`. Specifically, a [`SPSA`](https://qiskit.org/documentation/stubs/qiskit.algorithms.optimizers.SPSA.html) class performs gradient descent on the value returned by `cost_function` to determine the next iteration of $\\theta$ patameters to bind to the variational circuit.\n",
    "\n",
    "The cost of each iteration is stored and plotted below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizerLog:\n",
    "    \"\"\"Log to store optimizer's intermediate results\"\"\"\n",
    "    def __init__(self):\n",
    "        self.evaluations = []\n",
    "        self.parameters = []\n",
    "        self.costs = []\n",
    "    def update(self, evaluation, parameter, cost, _stepsize, _accept):\n",
    "        \"\"\"Save intermediate results. Optimizer passes five values\n",
    "        but we ignore the last two.\"\"\"\n",
    "        self.evaluations.append(evaluation)\n",
    "        self.parameters.append(parameter)\n",
    "        self.costs.append(cost)\n",
    "        \n",
    "def objective_function(variational):\n",
    "    \"\"\"Cost function of circuit parameters on training data.\n",
    "    The optimizer will attempt to minimize this.\"\"\"\n",
    "    return cost_function(train_data, train_labels, variational)\n",
    "\n",
    "# Set up the optimization\n",
    "from qiskit.algorithms.optimizers import SPSA\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def run_qml():\n",
    "    log = OptimizerLog()\n",
    "    optimizer = SPSA(maxiter=200, callback=log.update)\n",
    "\n",
    "    # Run the optimization\n",
    "    initial_point = np.random.rand(num_variational)\n",
    "    result = optimizer.minimize(objective_function, initial_point)\n",
    "\n",
    "    opt_var = result.x\n",
    "    opt_value = result.fun\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.plot(log.evaluations, log.costs)\n",
    "    plt.xlabel('Steps')\n",
    "    plt.ylabel('Cost')\n",
    "    plt.show()\n",
    "    \n",
    "    return opt_var, opt_value\n",
    "\n",
    "if local:\n",
    "    opt_var, opt_value = run_qml()\n",
    "else:\n",
    "    with Session(service=service, backend=backend):\n",
    "        sampler = Sampler()\n",
    "        opt_var, opt_value = run_qml()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the cost minimization plateaus rapidly. We have hit a ceiling for this variational circuit. Since it was originally meant to be a classifier, perhaps this is not surprising.\n",
    "\n",
    "Now that the circuit is trained, we can try plugging in our test dataset (instead of the training dataset) to see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = evaluation_probability(test_data, opt_var)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(test_labels, labels)\n",
    "\n",
    "x = np.linspace(0,1,100)\n",
    "plt.plot(x, x, '-r', label='ideal')\n",
    "\n",
    "plt.xlabel('Expected Values')\n",
    "plt.ylabel('Actual Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hm. Didn't seem to do that well. Ideally, we should see a 1:1 relationship between the expected vs measured evaluations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat the process with custom classification circuit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the NNUE-inspired circuit design, motivated solely by the previously-discussed constraints. The circuit is very shallow, owing to the lack of phase gates, which doesn't affect the final probability measurements, and that only 1 qubit is measured. Evaluation only needs to return a value between 0 and 1, so only 1 qubit is required for that. Thus, all other qubits besides the target need only be used to control that target, adhering to the contraint that qubits in their ground state much serve as $I$ gates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.circuit import Parameter\n",
    "\n",
    "QML = QuantumCircuit(num_qubits, 1)\n",
    "target = num_qubits - 1\n",
    "\n",
    "for i in range(num_qubits):\n",
    "    theta = Parameter(f'theta{i}')\n",
    "    \n",
    "    if i == target:\n",
    "        QML.ry(theta, target)\n",
    "    else:\n",
    "        QML.cry(theta, i, target)\n",
    "        \n",
    "QML.measure(target, 0)\n",
    "\n",
    "num_variational = num_qubits\n",
    "        \n",
    "QML.draw('mpl', reverse_bits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proceed to run this circuit through the same process as the control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if local:\n",
    "    opt_var, opt_value = run_qml()\n",
    "else:\n",
    "    with Session(service=service, backend=backend):\n",
    "        sampler = Sampler()\n",
    "        opt_var, opt_value = run_qml()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we see the shallower circuit marginally edge out the other circuit in terms of cost, but more importantly does not appear to be plateauing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = evaluation_probability(test_data, opt_var)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(test_labels, labels)\n",
    "\n",
    "x = np.linspace(0,1,100)\n",
    "plt.plot(x, x, '-r', label='ideal')\n",
    "\n",
    "plt.xlabel('Expected Values')\n",
    "plt.ylabel('Actual Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the fit still isn't very strong, suggesting more iterations may be required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "The key takeaway is that underlying variational circuit $W(\\overrightarrow{\\theta})$ is relatively arbitrary. Given a set of contraints, I was able to generate a completely different, shallower circuit that performs at least equivalent to the `TwoLocal` circuit used by IBM in their tutorial.\n",
    "\n",
    "Similar to classical machine learning, the structure of the circuit/network is largely determinate upon the problem to be solved, so while my NNUE-inspired circuit may perform relatively well at this task, it is equally possible that the control circuit would be better in other, perhaps more general, scenarios.\n",
    "\n",
    "As a learning exercise, however, I was successfully able to design my own QML circuit and train it to evaluate arbitrary input data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
